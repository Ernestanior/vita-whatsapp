import { logger } from '@/utils/logger';
import type { Message, MessageContext } from '@/types/whatsapp';
import { TextHandler } from './text-handler';
import { imageHandler } from './image-handler';
import { interactiveHandler } from './interactive-handler';
import { languageDetector } from '@/lib/language/detector';

/**
 * MessageRouter - Routes messages to appropriate handlers based on type
 * 
 * Responsibilities:
 * - Identify message type (text/image/interactive)
 * - Detect user language preference
 * - Route to appropriate handler
 * 
 * TEMPORARILY REVERTED: Using TextHandler instead of TextHandlerV2 to debug
 */
export class MessageRouter {
  private textHandler: TextHandler;

  constructor() {
    this.textHandler = new TextHandler();
  }

  /**
   * Route message to appropriate handler
   */
  async route(message: Message, context: MessageContext): Promise<void> {
    try {
      // Detect and update language from user's message
      if (message.type === 'text' && message.text?.body) {
        // Detect language from text and update user preference
        context.language = await languageDetector.detectAndUpdate(
          context.userId,
          message.text.body
        );
      } else {
        // For non-text messages, get user's saved language preference
        context.language = await languageDetector.getUserLanguage(context.userId);
      }

      logger.info({
        type: 'message_routing',
        messageId: message.id,
        messageType: message.type,
        language: context.language,
      });

      // Route based on message type
      switch (message.type) {
        case 'text':
          await this.textHandler.handle(message, context);
          break;

        case 'image':
          await imageHandler.handle(message, context);
          break;

        case 'interactive':
          await interactiveHandler.handle(message, context);
          break;

        case 'audio':
        case 'voice':
          // Handle voice messages - for now, prompt user to use text
          await this.handleVoiceMessage(message, context);
          break;

        default:
          logger.warn({
            type: 'unknown_message_type',
            messageType: message.type,
            messageId: message.id,
          });
      }
    } catch (error) {
      logger.error({
        type: 'routing_error',
        messageId: message.id,
        error: error instanceof Error ? error.message : 'Unknown error',
        stack: error instanceof Error ? error.stack : undefined,
      });
      throw error;
    }
  }

  /**
   * Handle voice/audio messages
   */
  private async handleVoiceMessage(
    message: Message,
    context: MessageContext
  ): Promise<void> {
    const messages = {
      'en': `ğŸ¤ Voice message received!

I can't process voice messages yet, but you can:

ğŸ“ Type: \`25 170 65\`
(age height weight)

Or

ğŸ“¸ Send a food photo to start

Coming soon: Voice recognition! ğŸš€`,
      
      'zh-CN': `ğŸ¤ æ”¶åˆ°è¯­éŸ³æ¶ˆæ¯ï¼

æˆ‘æš‚æ—¶è¿˜ä¸èƒ½å¤„ç†è¯­éŸ³æ¶ˆæ¯ï¼Œä½†æ‚¨å¯ä»¥ï¼š

ğŸ“ è¾“å…¥ï¼š\`25 170 65\`
ï¼ˆå¹´é¾„ èº«é«˜ ä½“é‡ï¼‰

æˆ–è€…

ğŸ“¸ å‘é€é£Ÿç‰©ç…§ç‰‡å¼€å§‹

å³å°†æ¨å‡ºï¼šè¯­éŸ³è¯†åˆ«ï¼ğŸš€`,
      
      'zh-TW': `ğŸ¤ æ”¶åˆ°èªéŸ³æ¶ˆæ¯ï¼

æˆ‘æš«æ™‚é‚„ä¸èƒ½è™•ç†èªéŸ³æ¶ˆæ¯ï¼Œä½†æ‚¨å¯ä»¥ï¼š

ğŸ“ è¼¸å…¥ï¼š\`25 170 65\`
ï¼ˆå¹´é½¡ èº«é«˜ é«”é‡ï¼‰

æˆ–è€…

ğŸ“¸ ç™¼é€é£Ÿç‰©ç…§ç‰‡é–‹å§‹

å³å°‡æ¨å‡ºï¼šèªéŸ³è­˜åˆ¥ï¼ğŸš€`,
    };

    const { whatsappClient } = await import('./client');
    await whatsappClient.sendTextMessage(
      context.userId,
      messages[context.language]
    );
  }

  /**
   * Get message type for logging/analytics
   */
  getMessageType(message: Message): string {
    if (message.type === 'text') {
      const text = message.text?.body || '';
      if (text.startsWith('/')) {
        return 'command';
      }
      return 'text';
    }
    return message.type;
  }
}

// Singleton instance
export const messageRouter = new MessageRouter();
